{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NollyKeyz/Simple-Python-Projects/blob/main/properly_cleaning_and_formating_an_email.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b256366-9f1e-4130-9513-b1e84e461e89",
      "metadata": {
        "id": "7b256366-9f1e-4130-9513-b1e84e461e89"
      },
      "source": [
        "## This is a simple text classification code for email data which has been properly formatted as a csv file. I have also provided a code to properly parse an email"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each of the lines of codes are properly explained as comments where neccessary"
      ],
      "metadata": {
        "id": "eeP8TFlHaBM0"
      },
      "id": "eeP8TFlHaBM0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3eeeca-9de8-44a4-bf23-a17d0ffd4723",
      "metadata": {
        "id": "8f3eeeca-9de8-44a4-bf23-a17d0ffd4723"
      },
      "outputs": [],
      "source": [
        "# importing important libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Be sure to replace the 'your_filename' with the appropriate csv filename**"
      ],
      "metadata": {
        "id": "R4GlxQNxb1Ez"
      },
      "id": "R4GlxQNxb1Ez"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89543715-8b5a-44b5-be2c-8989bf42ad47",
      "metadata": {
        "id": "89543715-8b5a-44b5-be2c-8989bf42ad47"
      },
      "outputs": [],
      "source": [
        "# read the csv file into a pandas dataframe\n",
        "\n",
        "email_document = pd.read_csv('your_filename.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Since this is an email data, it would most likely have a subject column. You can adjust to suit what you intend to see"
      ],
      "metadata": {
        "id": "4kBXAOShcf4D"
      },
      "id": "4kBXAOShcf4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820dc777-56a8-46f5-8c04-b2ac492aeb59",
      "metadata": {
        "id": "820dc777-56a8-46f5-8c04-b2ac492aeb59"
      },
      "outputs": [],
      "source": [
        "# obtain more information about the email document\n",
        "\n",
        "email_document['Subject']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6dd9d3-5b87-489e-9b7c-f5461ea98d96",
      "metadata": {
        "id": "3a6dd9d3-5b87-489e-9b7c-f5461ea98d96"
      },
      "outputs": [],
      "source": [
        "# Get an understanding of the data structure\n",
        "\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1787f8c2-4662-417f-8ad1-12fe61417d26",
      "metadata": {
        "id": "1787f8c2-4662-417f-8ad1-12fe61417d26"
      },
      "outputs": [],
      "source": [
        "# The shape typically shows 'rows x column dimension of your data\n",
        "\n",
        "print(email_document.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5fd38b7-bfc4-41c1-97c9-2122b7105d97",
      "metadata": {
        "id": "d5fd38b7-bfc4-41c1-97c9-2122b7105d97"
      },
      "source": [
        "#We'll need to carryout some preprocessing activities on our data\n",
        "\n",
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1158dd-a328-443a-874e-c704491fcd86",
      "metadata": {
        "id": "be1158dd-a328-443a-874e-c704491fcd86"
      },
      "outputs": [],
      "source": [
        "!pip install contractions\n",
        "\n",
        "import contractions # useful for single words containing certain characters\n",
        "import re # for implementing some of the preprocessing steps\n",
        "from string import punctuation # the punctuation is used to escape punctuation\n",
        "\n",
        "def clean_text(text):\n",
        "    # make text lowercase\n",
        "    text = str(text).lower()\n",
        "    #  remove HTML tags\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    # remove text in square brackets\n",
        "    text = re.sub('\\[.*?\\]', ' ', text)\n",
        "    # expand contractions especially for words with apostrophe\n",
        "    text = \" \".join([contractions.fix(expanded_word) for expanded_word in text.split()])\n",
        "    # remove links\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub('<.*?>+', ' ', text)\n",
        "    # remove new lines\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    # remove words containing numbers\n",
        "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
        "    # remove punctuation\n",
        "    text = re.sub('[%s]' % re.escape(punctuation), ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f95529-446a-466f-81b7-2c401d79a58b",
      "metadata": {
        "id": "a5f95529-446a-466f-81b7-2c401d79a58b"
      },
      "outputs": [],
      "source": [
        "# apply clean text fuction on each email in the training dataset\n",
        "email_document['Clean_Body'] = email_document['Body'].apply(lambda x:clean_text(x))\n",
        "email_document['Clean_Subject'] = email_document['Subject'].apply(lambda x:clean_text(x))\n",
        "\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The natural language toolkit (NLTK) is useful for working with human text data"
      ],
      "metadata": {
        "id": "mI6xen7ffVdK"
      },
      "id": "mI6xen7ffVdK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d9a7610-5dd3-4a80-930b-813f53ed8c0e",
      "metadata": {
        "id": "5d9a7610-5dd3-4a80-930b-813f53ed8c0e"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4beef920-080f-4ba5-85fd-d260a38ce619",
      "metadata": {
        "id": "4beef920-080f-4ba5-85fd-d260a38ce619"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# calculate the number of sentences for each email body and\n",
        "email_document['no_body_sentences'] = email_document['Clean_Body'].apply(lambda x: len(sent_tokenize(x)))\n",
        "email_document['no__subject_sentences'] = email_document['Clean_Subject'].apply(lambda x: len(sent_tokenize(x)))\n",
        "\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdcdea02-9142-4303-92ed-7c92653b3158",
      "metadata": {
        "id": "cdcdea02-9142-4303-92ed-7c92653b3158"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# tokenize each of the email into words\n",
        "email_document['email_body_words'] = email_document['Clean_Body'].apply(lambda x:word_tokenize(str(x)))\n",
        "email_document['subject_words'] = email_document['Clean_Subject'].apply(lambda x:word_tokenize(str(x)))\n",
        "\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4b4198-01a4-4367-ae3c-d9d759a6e574",
      "metadata": {
        "id": "dc4b4198-01a4-4367-ae3c-d9d759a6e574"
      },
      "outputs": [],
      "source": [
        "from collections import Counter # used for counting the frequency of words appearance\n",
        "\n",
        "top = Counter([item for sublist in email_document['email_body_words'] for item in sublist])\n",
        "temp_df = pd.DataFrame(top.most_common(40))\n",
        "temp_df.columns = ['Common_words','count']\n",
        "temp_df.style.background_gradient(cmap = 'Blues')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Words removal\n",
        "\n",
        "## Words such as 'and', 'the' etc which are not so relevant are removed for improved results"
      ],
      "metadata": {
        "id": "p2y6wFyBgHlS"
      },
      "id": "p2y6wFyBgHlS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ca2812-fe17-497c-b6ac-cd3ef59a9860",
      "metadata": {
        "id": "57ca2812-fe17-497c-b6ac-cd3ef59a9860"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords # i imported this to remove stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01968bd4-a994-482c-b68c-ee24703f6502",
      "metadata": {
        "id": "01968bd4-a994-482c-b68c-ee24703f6502"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['utf', 'b', 'q']) # replace the words with recurring unuseful words based on how your data is structured\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "  return [word for word in texts if word not in stop_words]\n",
        "\n",
        "email_document['email_body_without_sw'] = email_document['email_body_words'].apply(lambda x:remove_stopwords(x))\n",
        "email_document['subject_without_sw'] = email_document['subject_words'].apply(lambda x:remove_stopwords(x))\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tweak your own code depending on the results you intend to achieve with it\n",
        "\n",
        "## I am particularly interested in the email body and subject for the nature of my classification task"
      ],
      "metadata": {
        "id": "YO3gx4YYhWRD"
      },
      "id": "YO3gx4YYhWRD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "972597ea-e602-4130-9aad-b4913c349f2e",
      "metadata": {
        "id": "972597ea-e602-4130-9aad-b4913c349f2e"
      },
      "outputs": [],
      "source": [
        "# print the top ten most common words in the body of the email\n",
        "\n",
        "top = Counter([item for sublist in email_document['email_body_without_sw'] for item in sublist])\n",
        "temp_df = pd.DataFrame(top.most_common(40))\n",
        "temp_df.columns = ['Common_words','count']\n",
        "temp_df.style.background_gradient(cmap = 'Greens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995be4d3-508a-4991-a6c2-eed80005a918",
      "metadata": {
        "id": "995be4d3-508a-4991-a6c2-eed80005a918"
      },
      "outputs": [],
      "source": [
        "# print the top ten most common words in the subject of the email\n",
        "\n",
        "top = Counter([item for sublist in email_document['subject_without_sw'] for item in sublist])\n",
        "temp_df = pd.DataFrame(top.most_common(40))\n",
        "temp_df.columns = ['Common_words','count']\n",
        "temp_df.style.background_gradient(cmap = 'Reds')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function definition is necessary when dealing with some tasks.\n",
        "\n",
        "## In my case, I am dealing with four classes in relation to the kind of emails I received (social, religious/education, finance and then others which do not fall into any of the aforementioned category. Yours could be different"
      ],
      "metadata": {
        "id": "cRVH2prUhyaR"
      },
      "id": "cRVH2prUhyaR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9cbd9ec-f52f-42d4-80ae-3a7075d41381",
      "metadata": {
        "id": "b9cbd9ec-f52f-42d4-80ae-3a7075d41381"
      },
      "outputs": [],
      "source": [
        "def class_creation(subjects): # define a function for class creation\n",
        "\n",
        "  # Keywords for identifying different categories\n",
        "  social_keywords = ['facebook', 'email', 'emails', 'linkedin', 'post', 'twitter', 'commented', 'posts', 'page', 'invitation', 'invitations', 'posted', ]\n",
        "  religious_plus_education_keywords = ['proverb', 'school']\n",
        "  finance_keywords = ['transaction', 'gens', 'otp']\n",
        "\n",
        "  # Initialize list to store labelled subjects\n",
        "  result = []\n",
        "\n",
        "  for subject in subjects:\n",
        "    if any(keyword in subject for keyword in social_keywords):\n",
        "      result.append('social')\n",
        "    elif any(keyword in subject for keyword in religious_plus_education_keywords):\n",
        "      result.append('religious and education')\n",
        "    elif any(keyword in subject for keyword in finance_keywords):\n",
        "      result.append('finance')\n",
        "    else:\n",
        "      result.append('other updates')\n",
        "  return result\n",
        "\n",
        "\n",
        "email_document['class_labels'] = class_creation(email_document['subject_without_sw'])\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774a8b97-407f-4ad4-9d1c-12a33c5692c6",
      "metadata": {
        "id": "774a8b97-407f-4ad4-9d1c-12a33c5692c6"
      },
      "outputs": [],
      "source": [
        "def access_num_label(string_label): # a function to assign numerical labels to each of the classes\n",
        "  labels = []\n",
        "  for label in string_label:\n",
        "    if label == 'social':\n",
        "      labels.append(int(0))\n",
        "    elif label == 'finance':\n",
        "      labels.append(int(1))\n",
        "    elif label == 'religious and education':\n",
        "      labels.append(int(2))\n",
        "    elif label == 'other updates':\n",
        "      labels.append(int(3))\n",
        "  return labels\n",
        "\n",
        "email_document['label'] = access_num_label(email_document['class_labels'])\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa82112e-2c65-4b08-9bd3-94cbb1ed23e7",
      "metadata": {
        "id": "fa82112e-2c65-4b08-9bd3-94cbb1ed23e7"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "email_document['lemmatized_body'] = email_document['email_body_without_sw'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "email_document['lemmatized_subject'] = email_document['subject_without_sw'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5deab2-6b33-4c48-905b-e1359a91ec95",
      "metadata": {
        "id": "2e5deab2-6b33-4c48-905b-e1359a91ec95"
      },
      "outputs": [],
      "source": [
        "email_document['final_body'] = email_document['lemmatized_body'].apply(lambda x:' '.join(x))\n",
        "email_document['final_subject'] = email_document['lemmatized_subject'].apply(lambda x:' '.join(x))\n",
        "email_document.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I hope this helps\n",
        "\n",
        "# T for Thanks"
      ],
      "metadata": {
        "id": "i-UrVpCV0Rbn"
      },
      "id": "i-UrVpCV0Rbn"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "um7pumnynbtF"
      },
      "id": "um7pumnynbtF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}